"use strict";(self.webpackChunkinterview_prep=self.webpackChunkinterview_prep||[]).push([[8109],{3905:function(e,t,n){n.d(t,{Zo:function(){return c},kt:function(){return d}});var r=n(7294);function i(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function a(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,r)}return n}function o(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?a(Object(n),!0).forEach((function(t){i(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):a(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,r,i=function(e,t){if(null==e)return{};var n,r,i={},a=Object.keys(e);for(r=0;r<a.length;r++)n=a[r],t.indexOf(n)>=0||(i[n]=e[n]);return i}(e,t);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(r=0;r<a.length;r++)n=a[r],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(i[n]=e[n])}return i}var s=r.createContext({}),u=function(e){var t=r.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):o(o({},t),e)),n},c=function(e){var t=u(e.components);return r.createElement(s.Provider,{value:t},e.children)},p={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},m=r.forwardRef((function(e,t){var n=e.components,i=e.mdxType,a=e.originalType,s=e.parentName,c=l(e,["components","mdxType","originalType","parentName"]),m=u(n),d=i,f=m["".concat(s,".").concat(d)]||m[d]||p[d]||a;return n?r.createElement(f,o(o({ref:t},c),{},{components:n})):r.createElement(f,o({ref:t},c))}));function d(e,t){var n=arguments,i=t&&t.mdxType;if("string"==typeof e||i){var a=n.length,o=new Array(a);o[0]=m;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l.mdxType="string"==typeof e?e:i,o[1]=l;for(var u=2;u<a;u++)o[u]=n[u];return r.createElement.apply(null,o)}return r.createElement.apply(null,n)}m.displayName="MDXCreateElement"},7940:function(e,t,n){n.r(t),n.d(t,{assets:function(){return c},contentTitle:function(){return s},default:function(){return d},frontMatter:function(){return l},metadata:function(){return u},toc:function(){return p}});var r=n(7462),i=n(3366),a=(n(7294),n(3905)),o=["components"],l={title:"Testing after production",description:"Why testing in production (rather than before deploying) could make sense in some cases",last_modified:new Date("2022-01-02T14:25:32.148Z")},s=void 0,u={unversionedId:"processes-techniques/testing-details/testing-after-production",id:"processes-techniques/testing-details/testing-after-production",title:"Testing after production",description:"Why testing in production (rather than before deploying) could make sense in some cases",source:"@site/docs/processes-techniques/testing-details/testing-after-production.md",sourceDirName:"processes-techniques/testing-details",slug:"/processes-techniques/testing-details/testing-after-production",permalink:"/interview-prep/processes-techniques/testing-details/testing-after-production",draft:!1,tags:[],version:"current",frontMatter:{title:"Testing after production",description:"Why testing in production (rather than before deploying) could make sense in some cases",last_modified:"2022-01-02T14:25:32.148Z"},sidebar:"docs",previous:{title:"Trunk Based Development",permalink:"/interview-prep/processes-techniques/trunk-based-development"},next:{title:"Testing patterns",permalink:"/interview-prep/processes-techniques/testing-details/testing-patterns"}},c={},p=[{value:"Basic idea",id:"basic-idea",level:2},{value:"Mean time between failures versus mean time to repair",id:"mean-time-between-failures-versus-mean-time-to-repair",level:2},{value:"Separating deployment from release",id:"separating-deployment-from-release",level:2},{value:"Monitoring and logging",id:"monitoring-and-logging",level:2},{value:"Synthetic monitoring",id:"synthetic-monitoring",level:2},{value:"Resources",id:"resources",level:2}],m={toc:p};function d(e){var t=e.components,n=(0,i.Z)(e,o);return(0,a.kt)("wrapper",(0,r.Z)({},m,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Why testing in production (rather than before deploying) could make sense in some cases"),(0,a.kt)("h2",{id:"basic-idea"},"Basic idea"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Tests will never be perfect, we can't catch everything! Impossible to reduce chance of failure to zero"),(0,a.kt)("li",{parentName:"ul"},"It might be impractical and not worth the effort to test certain things before putting them in production")),(0,a.kt)("h2",{id:"mean-time-between-failures-versus-mean-time-to-repair"},"Mean time between failures versus mean time to repair"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Mean time between failures (MTBF): indication of how often issues make it to production"),(0,a.kt)("li",{parentName:"ul"},"Mean time to repair (MTTR): indication of how long it takes you to detect and fix such issues")),(0,a.kt)("p",null,"Tradeoff MTBF versus MTTR:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Sometimes, it's more efficient to spend effort on getting better at detecting and fixing issues in production than on adding more automated tests"),(0,a.kt)("li",{parentName:"ul"},"Best tradeoff depends on your organization"),(0,a.kt)("li",{parentName:"ul"},"Do not completely abandon one in favor of the other",(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},"It's probably not a good idea to just throw stuff into production without any level of testing"),(0,a.kt)("li",{parentName:"ul"},"Even with great tests, you need to be prepared for a bug popping up in production")))),(0,a.kt)("h2",{id:"separating-deployment-from-release"},"Separating deployment from release"),(0,a.kt)("p",null,"Basic idea: after deploying something, don't immediately direct full production load to it"),(0,a.kt)("p",null,"Useful techniques:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("strong",{parentName:"li"},"Smoke tests"),":",(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},"Tests designed to check that deployment was successful and software runs properly in current environment"),(0,a.kt)("li",{parentName:"ul"},"Should ideally be run automatically on deploy"))),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("strong",{parentName:"li"},"Blue/green deployment"),":",(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},"Run old and new next to each other"),(0,a.kt)("li",{parentName:"ul"},"New can get smoke tested while old still handles production load, then we can switch"),(0,a.kt)("li",{parentName:"ul"},"After switching to new, we can quickly switch back if necessary"))),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("strong",{parentName:"li"},"Canary releasing"),":",(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},"Keep old and new next to each other for longer time"),(0,a.kt)("li",{parentName:"ul"},"Only direct a fraction of production load to new, increase as confidence increases"))),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("strong",{parentName:"li"},"Branch By Abstraction")," and ",(0,a.kt)("strong",{parentName:"li"},"application strangulation")," (see ",(0,a.kt)("a",{parentName:"li",href:"/processes-techniques/branch-by-abstraction-application-strangulation"},"Branch By Abstraction and application strangulation"),"):",(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},"Techniques to gradually migrate to new code or even new system"),(0,a.kt)("li",{parentName:"ul"},"Possible to direct production traffic to existing code/system but also send a copy of it to new code/system to check for differences in behavior")))),(0,a.kt)("h2",{id:"monitoring-and-logging"},"Monitoring and logging"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Monitor CPU, memory, ..."),(0,a.kt)("li",{parentName:"ul"},"Monitor application itself: response time, number of errors returned to client, number of submitted forms, ..."),(0,a.kt)("li",{parentName:"ul"},"Collect logs about what the system is doing",(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},"It's especially important to log any errors that happen"))),(0,a.kt)("li",{parentName:"ul"},"Set up dashboards so people can quickly get an idea of the system's state"),(0,a.kt)("li",{parentName:"ul"},"Set up alerts based on resource use, response time, error rates, 500 responses, ...",(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},"Alert early enough so team can act before things really get bad"),(0,a.kt)("li",{parentName:"ul"},"Watch your signal-to-noise ratio, so people don't start ignoring alerts")))),(0,a.kt)("h2",{id:"synthetic-monitoring"},"Synthetic monitoring"),(0,a.kt)("p",null,"(also called ",(0,a.kt)("strong",{parentName:"p"},"semantic monitoring"),")"),(0,a.kt)("p",null,"Basic idea: monitor health of system as whole by running end-to-end scenarios against it"),(0,a.kt)("p",null,"Approach:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Define important scenarios or user journeys"),(0,a.kt)("li",{parentName:"ul"},"Write tests for them (often make sense to start from end-to-end tests)"),(0,a.kt)("li",{parentName:"ul"},"Periodically run these against production",(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},"Depending on importance of scenario or journey, failure can trigger on-call alert")))),(0,a.kt)("p",null,"Benefits/challenges:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Often way better at finding out if something's wrong than lower-level metrics",(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},"Still, you'll likely need lower-level metrics to help you find the exact location of the issue"))),(0,a.kt)("li",{parentName:"ul"},"Make sure it doesn't affect actual production customers!")),(0,a.kt)("h2",{id:"resources"},"Resources"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Martin Fowler's ",(0,a.kt)("a",{href:"https://martinfowler.com/testing/",target:"_blank",rel:"nofollow noopener noreferrer"},"Software Testing Guide ",(0,a.kt)("svg",{class:"embedded-fa-icon"},(0,a.kt)("use",{href:"#external-link-alt"}))),":",(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{href:"https://martinfowler.com/articles/qa-in-production.html",target:"_blank",rel:"nofollow noopener noreferrer"},"QA in Production ",(0,a.kt)("svg",{class:"embedded-fa-icon"},(0,a.kt)("use",{href:"#external-link-alt"})))),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{href:"https://martinfowler.com/bliki/SyntheticMonitoring.html",target:"_blank",rel:"nofollow noopener noreferrer"},"Synthetic Monitoring ",(0,a.kt)("svg",{class:"embedded-fa-icon"},(0,a.kt)("use",{href:"#external-link-alt"})))))),(0,a.kt)("li",{parentName:"ul"},"Building Microservices (book by Sam Newman)")))}d.isMDXComponent=!0}}]);